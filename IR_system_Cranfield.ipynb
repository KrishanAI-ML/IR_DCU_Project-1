{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnsbAIm87kmP17PTte6DD7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrishanAI-ML/IR_DCU_Project-1/blob/main/IR_system_Cranfield.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxz12GpnJVoN",
        "outputId": "814fbef8-4776-4018-b655-7a7b4d89a2c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import nltk\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from collections import defaultdict\n",
        "from operator import itemgetter\n",
        "from nltk.tokenize import word_tokenize\n",
        "import subprocess\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the data directory\n",
        "data_path = '/content/drive/MyDrive/DCU_IR_PROJECT'\n",
        "\n",
        "# Define the file paths for the Cranfield collection\n",
        "data_file = os.path.join(data_path, 'cran.all.1400')  # Path to the Cranfield document collection\n",
        "query_file = os.path.join(data_path, 'cran.qry')       # Path to the Cranfield query file\n",
        "comp_file = os.path.join(data_path, 'cranqrel')        # Path to the Cranfield relevance judgments file\n",
        "\n",
        "# Define the directory paths for storing processed data\n",
        "Formated_Document = os.path.join(data_path, 'Formated Documents')  # Path to store formatted documents\n",
        "PreProcessed_Documents = os.path.join(data_path, 'PreProcessed_Documents')  # Path to store preprocessed documents\n",
        "Output_Directory = os.path.join(data_path, 'Output_Directory')      # Path to store output files\n"
      ],
      "metadata": {
        "id": "cPcT-xJQJ0k0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_passage(data_file):\n",
        "  \"\"\"Loads passage data from a file.\n",
        "\n",
        "  This function reads a file containing passage data and returns a dictionary\n",
        "  where keys are document IDs and values are the corresponding text data.\n",
        "\n",
        "  Args:\n",
        "      data_file (str): The path to the file containing passage data.\n",
        "\n",
        "  Returns:\n",
        "      dict: A dictionary containing document IDs as keys and text data as values.\n",
        "  \"\"\"\n",
        "\n",
        "  # Open the data file in read mode with UTF-8 encoding\n",
        "  with open(data_file, 'r', encoding='utf-8') as file:\n",
        "    # Read the entire content of the file into a string\n",
        "    passage = file.read().split('.I')[1:]\n",
        "\n",
        "  # Create an empty dictionary to store document data\n",
        "  Data = {}\n",
        "\n",
        "  # Iterate over each passage in the file (excluding the first element)\n",
        "  for sequence, doc_data in enumerate(passage, start=1):\n",
        "    # Split the passage data into Document ID and Text Data using '.T\\n' delimiter\n",
        "    Document_ID, TextData = doc_data.split('.T\\n')\n",
        "    # Remove any leading/trailing whitespaces from Document ID\n",
        "    Document_ID = Document_ID.strip()\n",
        "    # Remove any leading/trailing whitespaces from Text Data\n",
        "    TextData = TextData.strip()\n",
        "    # Add the Document ID as key and Text Data as value to the dictionary\n",
        "    Data[Document_ID] = TextData\n",
        "\n",
        "    # Check if the 'Formated Documents' directory exists\n",
        "    if not os.path.exists(Formated_Document):\n",
        "      # Create the 'Formated Documents' directory if it doesn't exist\n",
        "      os.makedirs(Formated_Document)\n",
        "\n",
        "    # Construct the file path for the current document\n",
        "    Document_File = os.path.join(Formated_Document, f'{Document_ID}.txt')\n",
        "\n",
        "    # Open the document file in write mode with UTF-8 encoding\n",
        "    with open(Document_File, 'w', encoding='utf-8') as f:\n",
        "      # Write the Text Data of the document to the file\n",
        "      f.write(TextData)\n",
        "\n",
        "  # uncomment this line to print the loaded data for verification\n",
        "  # print(Data)\n",
        "  # Return the dictionary containing document IDs and Text Data\n",
        "  return Data\n"
      ],
      "metadata": {
        "id": "LFsF-kcfK1vu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PreProcessing_Text(Document_ID, Text):\n",
        "  \"\"\"Preprocesses text data for information retrieval tasks.\n",
        "\n",
        "  This function performs the following steps on the input text:\n",
        "      1. Tokenization: Splits the text into individual words.\n",
        "      2. Stop word removal: Removes common words (stop words) from the tokens.\n",
        "      3. Stemming: Reduces words to their base forms (e.g., \"running\" -> \"run\").\n",
        "      4. Saves the preprocessed text to a file.\n",
        "\n",
        "  Args:\n",
        "      Document_ID (str): The ID of the document being processed.\n",
        "      Text (str): The text data to be preprocessed.\n",
        "\n",
        "  Returns:\n",
        "      list: A list of stemmed tokens (words) after preprocessing.\n",
        "  \"\"\"\n",
        "\n",
        "  # Tokenize the text into lowercase words using NLTK word_tokenize\n",
        "  # Lowercasing helps improve stemming accuracy\n",
        "  Tokenizer = word_tokenize(Text.lower())\n",
        "\n",
        "  # Load the stop words list from NLTK stopwords corpus for English\n",
        "  StopWords = set(stopwords.words('english'))\n",
        "\n",
        "  # Filter out stop words from the tokenized text\n",
        "  Filtered_Tokens = []\n",
        "  for Token in Tokenizer:\n",
        "    if Token not in StopWords:  # Check if token is not a stop word\n",
        "      Filtered_Tokens.append(Token)\n",
        "\n",
        "  # Create a Porter Stemmer object for stemming words\n",
        "  Stemmer = PorterStemmer()\n",
        "\n",
        "  # Apply stemming to each filtered token\n",
        "  Stemmed_Tokens = []\n",
        "  for Token in Filtered_Tokens:\n",
        "    Stemmed_Tokens.append(Stemmer.stem(Token))\n",
        "\n",
        "  # Check if the 'PreProcessed_Documents' directory exists\n",
        "  if not os.path.exists(PreProcessed_Documents):\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(PreProcessed_Documents)\n",
        "\n",
        "  # Construct the file path for the preprocessed document\n",
        "  Document_file = os.path.join(PreProcessed_Documents, f'{Document_ID}.txt')\n",
        "\n",
        "  # Open the file in write mode with UTF-8 encoding\n",
        "  with open(Document_file, 'w', encoding='utf-8') as f:\n",
        "    # Write the preprocessed text as a space-separated string to the file\n",
        "    f.write(' '.join(Stemmed_Tokens))\n",
        "\n",
        "  # uncomment this line to print the stemmed tokens for verification\n",
        "  # print(Stemmed_Tokens)\n",
        "  # Return the list of stemmed tokens\n",
        "  return Stemmed_Tokens\n"
      ],
      "metadata": {
        "id": "_FU2MWKMLt7t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Module_Inverted_Index(Text):\n",
        "  \"\"\"Creates an inverted index from a dictionary of document data.\n",
        "\n",
        "  This function takes a dictionary where keys are document IDs and values\n",
        "  are text data, preprocesses the text, and builds an inverted index where\n",
        "  keys are unique tokens and values are lists of document IDs containing those tokens.\n",
        "\n",
        "  Args:\n",
        "      Text (dict): A dictionary containing document IDs and text data.\n",
        "\n",
        "  Returns:\n",
        "      defaultdict: The inverted index with tokens as keys and lists of document IDs as values.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create an empty inverted index using a defaultdict for efficient handling of missing keys\n",
        "  InvertedIndex = defaultdict(list)\n",
        "\n",
        "  # Iterate through each document ID and text data pair in the input dictionary\n",
        "  for Document_ID, Paragraph in Text.items():\n",
        "    # Preprocess the text (tokenize, remove stop words, and stem)\n",
        "    Tokens = PreProcessing_Text(Document_ID, Paragraph)\n",
        "\n",
        "    # Iterate through each token in the preprocessed text\n",
        "    for Token in Tokens:\n",
        "      # Check if the document ID is not already associated with the token in the inverted index\n",
        "      if Document_ID not in InvertedIndex[Token]:\n",
        "        # Add the document ID to the list of documents for the token\n",
        "        InvertedIndex[Token].append(Document_ID)\n",
        "\n",
        "  # uncomment this line to print the inverted index for verification\n",
        "  # print(InvertedIndex)\n",
        "\n",
        "  # Return the completed inverted index\n",
        "  return InvertedIndex\n"
      ],
      "metadata": {
        "id": "6XZogK9aMDOD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Calculate_InverseDocumentFrequency(Invert_Index, NumberOfDocuments):\n",
        "  \"\"\"Calculates Inverse Document Frequency (IDF) for each token in the inverted index.\n",
        "\n",
        "  This function iterates through the inverted index and calculates the IDF score\n",
        "  for each token. IDF is a measure of a term's importance based on how frequently\n",
        "  it appears across documents in a collection.\n",
        "\n",
        "  Args:\n",
        "      Invert_Index (defaultdict): The inverted index with tokens as keys and lists of document IDs as values.\n",
        "      NumberOfDocuments (int): The total number of documents in the collection.\n",
        "\n",
        "  Returns:\n",
        "      dict: A dictionary containing tokens as keys and their corresponding IDF scores as values.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create an empty dictionary to store IDF scores\n",
        "  InverseDocumentFrequency = {}\n",
        "\n",
        "  # Iterate through each token and its associated document list in the inverted index\n",
        "  for Token, Document_List in Invert_Index.items():\n",
        "\n",
        "    # Calculate IDF using the formula: IDF = log(Total Documents / (Documents containing term + 1))\n",
        "    # Add 1 to the denominator to avoid division by zero for terms appearing in all documents\n",
        "    InverseDocumentFrequency[Token] = math.log(NumberOfDocuments / (len(Document_List) + 1))\n",
        "\n",
        "  # uncomment this line to print the IDF scores for verification\n",
        "  # print(InverseDocumentFrequency)\n",
        "\n",
        "  # Return the dictionary containing tokens and their IDF scores\n",
        "  return InverseDocumentFrequency\n"
      ],
      "metadata": {
        "id": "MMsq-jYpMboM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Load_Queries(query_file):\n",
        "  \"\"\"Loads queries from a file.\n",
        "\n",
        "  This function reads a file containing queries and returns a dictionary\n",
        "  where keys are query IDs and values are the corresponding query text.\n",
        "\n",
        "  Args:\n",
        "      query_file (str): The path to the file containing queries.\n",
        "\n",
        "  Returns:\n",
        "      dict: A dictionary containing query IDs as keys and query text as values.\n",
        "  \"\"\"\n",
        "\n",
        "  # Open the query file in read mode with UTF-8 encoding\n",
        "  with open(query_file, 'r', encoding='utf-8') as file:\n",
        "    # Read the entire content of the file into a string\n",
        "    Queries = file.read().split('.I')[1:]  # Split by \".I\" delimiter, excluding the first element\n",
        "\n",
        "  # Create an empty dictionary to store queries\n",
        "  Queries_Dictionary = {}\n",
        "\n",
        "  # Iterate over each query in the file (excluding the first element)\n",
        "  for Query in Queries:\n",
        "    # Split the query data into Query ID and Query Content using \".W\\n\" delimiter\n",
        "    QueryID, QueryContent = Query.split('.W\\n')\n",
        "    # Remove any leading/trailing whitespaces from Query ID\n",
        "    QueryID = QueryID.strip()\n",
        "    # Remove any leading/trailing whitespaces from Query Content\n",
        "    QueryContent = QueryContent.strip()\n",
        "    # Add the Query ID as key and Query Content as value to the dictionary\n",
        "    Queries_Dictionary[QueryID] = QueryContent\n",
        "\n",
        "  # uncomment this line to print the loaded queries for verification\n",
        "  # print(Queries_Dictionary)\n",
        "  # Return the dictionary containing query IDs and query text\n",
        "  return Queries_Dictionary\n"
      ],
      "metadata": {
        "id": "WLp2YUpRMsoi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Calculate_TermFrequency(Query_Token):\n",
        "  \"\"\"Calculates term frequencies for tokens in a query.\n",
        "\n",
        "  This function counts the occurrences of each unique token in a query and\n",
        "  returns a dictionary containing token frequencies.\n",
        "\n",
        "  Args:\n",
        "      Query_Token (list): A list of tokens representing a query.\n",
        "\n",
        "  Returns:\n",
        "      defaultdict: A dictionary where keys are tokens and values are their term frequencies.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create an empty dictionary using defaultdict to efficiently handle missing keys\n",
        "  TermFrequency = defaultdict(int)\n",
        "\n",
        "  # Iterate through each token in the query\n",
        "  for Token in Query_Token:\n",
        "    # Increment the count for the token in the TermFrequency dictionary\n",
        "    TermFrequency[Token] += 1\n",
        "\n",
        "  # Return the dictionary containing token frequencies\n",
        "  return TermFrequency\n"
      ],
      "metadata": {
        "id": "wNK8StMiNBAC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Module_Term_Document_Matrix(Documents, Inverted_Index, InverseDocumentFrequency):\n",
        "  \"\"\"Creates a term-document matrix (TDM) from documents, inverted index, and IDF scores.\n",
        "\n",
        "  This function builds a TDM where rows represent terms, columns represent documents,\n",
        "  and each cell contains the product of term frequency (TF) and inverse document frequency (IDF)\n",
        "  for a specific term-document pair.\n",
        "\n",
        "  Args:\n",
        "      Documents (dict): A dictionary containing document IDs and text data.\n",
        "      Inverted_Index (defaultdict): The inverted index with tokens as keys and lists of document IDs as values.\n",
        "      InverseDocumentFrequency (dict): A dictionary containing tokens as keys and their corresponding IDF scores as values.\n",
        "\n",
        "  Returns:\n",
        "      defaultdict(dict): The term-document matrix with terms as rows, documents as columns,\n",
        "                          and TF-IDF values in each cell.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create an empty defaultdict to store the term-document matrix\n",
        "  TermDocumentMatrix = defaultdict(dict)\n",
        "\n",
        "  # Iterate through each document ID and text data pair in the Documents dictionary\n",
        "  for Document_ID, Document_Content in Documents.items():\n",
        "\n",
        "    # Preprocess the text data for the current document (tokenize, remove stop words, and stem)\n",
        "    Tokens = PreProcessing_Text(Document_ID, Document_Content)\n",
        "\n",
        "    # Calculate term frequencies for tokens in the document\n",
        "    TermFrequency = Calculate_TermFrequency(Tokens)\n",
        "\n",
        "    # Iterate through each token and its frequency in the document\n",
        "    for Token, Frequency in TermFrequency.items():\n",
        "\n",
        "      # Check if the IDF score exists for the token in the IDF dictionary\n",
        "      if Token in InverseDocumentFrequency:\n",
        "        # Calculate TF-IDF by multiplying term frequency and IDF score\n",
        "        TermFrequencyInverseDocumentFrequency = Frequency * InverseDocumentFrequency[Token]\n",
        "\n",
        "        # Add the TF-IDF value to the TDM for the current token and document\n",
        "        TermDocumentMatrix[Token][Document_ID] = TermFrequencyInverseDocumentFrequency\n",
        "\n",
        "  # Return the completed term-document matrix\n",
        "  return TermDocumentMatrix\n"
      ],
      "metadata": {
        "id": "qjqyzVq7NQ1O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def VSM_DocumentRanking(Query_Tokens, Term_Document_Matrix):\n",
        "  \"\"\"Ranks documents based on their similarity to a query using Vector Space Model (VSM).\n",
        "\n",
        "  This function calculates a score for each document in the collection based on the\n",
        "  query terms. The score considers the term frequencies in documents (TF-IDF from the TDM)\n",
        "  and aims to identify documents most relevant to the query.\n",
        "\n",
        "  Args:\n",
        "      Query_Tokens (list): A list of tokens representing the query.\n",
        "      Term_Document_Matrix (defaultdict(dict)): The term-document matrix with terms as rows,\n",
        "                                                documents as columns, and TF-IDF values in each cell.\n",
        "\n",
        "  Returns:\n",
        "      list: A list of tuples containing document IDs and their corresponding scores,\n",
        "            sorted in descending order of score (highest scoring documents first).\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a dictionary to store document scores with document IDs as keys and scores as values\n",
        "  Document_Score = defaultdict(float)\n",
        "\n",
        "  # Iterate through each unique token in the query\n",
        "  for Token in Query_Tokens:\n",
        "\n",
        "    # Check if the token exists in the term-document matrix (avoiding potential KeyError)\n",
        "    if Token in Term_Document_Matrix:\n",
        "      # Iterate through each document ID and TF-IDF value associated with the token in the TDM\n",
        "      for Document_ID, TFIDF in Term_Document_Matrix[Token].items():\n",
        "        # Accumulate the TF-IDF contribution of the current token to the document's score\n",
        "        Document_Score[Document_ID] += TFIDF\n",
        "\n",
        "  # Sort the document scores in descending order (highest scoring documents first)\n",
        "  # Use itemgetter(1) to sort based on the second element in each tuple (the score)\n",
        "  Ranked_Documents = sorted(Document_Score.items(), key=itemgetter(1), reverse=True)\n",
        "\n",
        "  # Return the list of ranked documents (document ID, score)\n",
        "  return Ranked_Documents\n"
      ],
      "metadata": {
        "id": "Vbn9kazqN1FZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Output_File(Query_ID, Document_Ranking, Model, Output_Directory):\n",
        "  \"\"\"Writes ranked documents to an output file in TREC format.\n",
        "\n",
        "  This function takes a query ID, ranked documents (list of tuples with document ID and score),\n",
        "  the model name (e.g., \"VSM\"), and the output directory. It creates the output directory if it\n",
        "  doesn't exist and writes the ranked documents to a file in TREC format, which is a standard\n",
        "  format for information retrieval evaluation.\n",
        "\n",
        "  Args:\n",
        "      Query_ID (str): The ID of the query.\n",
        "      Document_Ranking (list): A list of tuples containing document IDs and their corresponding scores.\n",
        "      Model (str): The name of the retrieval model used (e.g., \"VSM\").\n",
        "      Output_Directory (str): The path to the directory for storing output files.\n",
        "  \"\"\"\n",
        "\n",
        "  # Check if the output directory exists, create it if not\n",
        "  if not os.path.exists(Output_Directory):\n",
        "    os.makedirs(Output_Directory)\n",
        "\n",
        "  # Construct the output file path with the model name appended\n",
        "  Output_File = os.path.join(Output_Directory, f'{Model}_output.txt')\n",
        "\n",
        "  # Open the output file in append mode (a)\n",
        "  with open(Output_File, 'a') as f:\n",
        "    # Iterate through each document in the ranked list (starting rank from 1)\n",
        "    for Rank, (Document_ID, Document_Score) in enumerate(Document_Ranking, start=1):\n",
        "      # Define unused variables (could be used for future extensions)\n",
        "      Iteration_Value = 0\n",
        "      Run_ID_Value = 'Information_Retrival_System'\n",
        "      Rank_Value = Rank\n",
        "\n",
        "      # Write each document information in TREC format to the file\n",
        "      f.write(f\"{Query_ID} {Iteration_Value} {Document_ID} {Rank_Value} {Document_Score:.6f} {Run_ID_Value + Model}\\n\")\n",
        "\n",
        "  # No return value needed as the function modifies the file directly\n"
      ],
      "metadata": {
        "id": "8N47skKLOF-M"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BM25_DocumentRanking(QueryTokens, Documents, Inverted_Index, NumberOfDocuments, AverageDocumentLength):\n",
        "  \"\"\"Ranks documents based on their similarity to a query using BM25 model.\n",
        "\n",
        "  This function implements the BM25 (Best Match 25) document ranking algorithm.\n",
        "  It calculates a score for each document in the collection based on the query terms\n",
        "  and factors like document length and term frequency.\n",
        "\n",
        "  Args:\n",
        "      QueryTokens (list): A list of tokens representing the query.\n",
        "      Documents (dict): A dictionary containing document IDs and text data.\n",
        "      Inverted_Index (defaultdict): The inverted index with tokens as keys and lists of document IDs as values.\n",
        "      NumberOfDocuments (int): The total number of documents in the collection.\n",
        "      AverageDocumentLength (float): The average document length in the collection.\n",
        "\n",
        "  Returns:\n",
        "      list: A list of tuples containing document IDs and their corresponding scores,\n",
        "            sorted in descending order of score (highest scoring documents first).\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a dictionary to store document scores with document IDs as keys and scores as values\n",
        "  DocumentScore = defaultdict(float)\n",
        "\n",
        "  # Iterate through each document ID and text data pair in the Documents dictionary\n",
        "  for DocumentID, DocumentContent in Documents.items():\n",
        "\n",
        "    # Preprocess the text data for the current document (tokenize, remove stop words, and stem)\n",
        "    DocumentTokens = PreProcessing_Text(DocumentID, DocumentContent)\n",
        "\n",
        "    # Calculate BM25 score for the document based on the query, document tokens, etc.\n",
        "    DocScore = BM25_ScoreCalculation(QueryTokens, DocumentTokens, Inverted_Index, NumberOfDocuments, AverageDocumentLength)\n",
        "\n",
        "    # Add the BM25 score for the document to the DocumentScore dictionary\n",
        "    DocumentScore[DocumentID] = DocScore\n",
        "\n",
        "  # Sort the document scores in descending order (highest scoring documents first)\n",
        "  # Use itemgetter(1) to sort based on the second element in each tuple (the score)\n",
        "  DocumentRanking = sorted(DocumentScore.items(), key=itemgetter(1), reverse=True)\n",
        "\n",
        "  # Return the list of ranked documents (document ID, score)\n",
        "  return DocumentRanking\n"
      ],
      "metadata": {
        "id": "18SX6XihOaBg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BM25_DocumentRanking(QueryTokens, Documents, Inverted_Index, NumberOfDocuments, AverageDocumentLength):\n",
        "  \"\"\"Ranks documents based on their similarity to a query using BM25 model.\n",
        "\n",
        "  This function implements the BM25 (Best Match 25) document ranking algorithm.\n",
        "  It calculates a score for each document in the collection based on the query terms\n",
        "  and factors like document length and term frequency.\n",
        "\n",
        "  Args:\n",
        "      QueryTokens (list): A list of tokens representing the query.\n",
        "      Documents (dict): A dictionary containing document IDs and text data.\n",
        "      Inverted_Index (defaultdict): The inverted index with tokens as keys and lists of document IDs as values.\n",
        "      NumberOfDocuments (int): The total number of documents in the collection.\n",
        "      AverageDocumentLength (float): The average document length in the collection.\n",
        "\n",
        "  Returns:\n",
        "      list: A list of tuples containing document IDs and their corresponding scores,\n",
        "            sorted in descending order of score (highest scoring documents first).\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a dictionary to store document scores with document IDs as keys and scores as values\n",
        "  DocumentScore = defaultdict(float)\n",
        "\n",
        "  # Iterate through each document ID and text data pair in the Documents dictionary\n",
        "  for DocumentID, DocumentContent in Documents.items():\n",
        "\n",
        "    # Preprocess the text data for the current document (tokenize, remove stop words, and stem)\n",
        "    DocumentTokens = PreProcessing_Text(DocumentID, DocumentContent)\n",
        "\n",
        "    # Calculate BM25 score for the document based on the query, document tokens, etc.\n",
        "    # (Assuming BM25_ScoreCalculation is defined elsewhere)\n",
        "    DocScore = BM25_ScoreCalculation(QueryTokens, DocumentTokens, Inverted_Index, NumberOfDocuments, AverageDocumentLength)\n",
        "\n",
        "    # Add the BM25 score for the document to the DocumentScore dictionary\n",
        "    DocumentScore[DocumentID] = DocScore\n",
        "\n",
        "  # Sort the document scores in descending order (highest scoring documents first)\n",
        "  # Use itemgetter(1) to sort based on the second element in each tuple (the score)\n",
        "  DocumentRanking = sorted(DocumentScore.items(), key=itemgetter(1), reverse=True)\n",
        "\n",
        "  # Return the list of ranked documents (document ID, score)\n",
        "  return DocumentRanking\n"
      ],
      "metadata": {
        "id": "NQxL4eTFOui7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BM25_ScoreCalculation(QueryTokens, DocumentTokens, Inverted_Index, NumberOfDocuments, AverageDocumentLength, k1=1.5, b=0.75):\n",
        "  \"\"\"Calculates the BM25 score for a document given a query and collection parameters.\n",
        "\n",
        "  This function implements the BM25 (Best Match 25) document scoring formula.\n",
        "  It considers factors like query terms, document frequency (DF), inverse document frequency (IDF),\n",
        "  term frequency (TF) within the document, document length, and average document length in the collection.\n",
        "\n",
        "  Args:\n",
        "      QueryTokens (list): A list of tokens representing the query.\n",
        "      DocumentTokens (list): A list of tokens representing the preprocessed document text.\n",
        "      Inverted_Index (defaultdict): The inverted index with tokens as keys and lists of document IDs as values.\n",
        "      NumberOfDocuments (int): The total number of documents in the collection.\n",
        "      AverageDocumentLength (float): The average document length in the collection.\n",
        "      k1 (float, optional): BM25 parameter controlling term frequency scaling (default 1.5).\n",
        "      b (float, optional): BM25 parameter controlling document length impact (default 0.75).\n",
        "\n",
        "  Returns:\n",
        "      float: The BM25 score for the document relative to the query.\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize document score to 0\n",
        "  DocumentScore = 0\n",
        "\n",
        "  # Get the length of the document (number of tokens)\n",
        "  DocumentLength = len(DocumentTokens)\n",
        "\n",
        "  # Iterate through each unique token in the query\n",
        "  for Token in QueryTokens:\n",
        "\n",
        "    # Get the document frequency (number of documents containing the token) from the inverted index\n",
        "    DocumentFrequency = len(Inverted_Index[Token])\n",
        "\n",
        "    # Calculate IDF (inverse document frequency) using smoothing to avoid division by zero\n",
        "    InverseDocumentFrequency = math.log((NumberOfDocuments - DocumentFrequency + 0.5) / (DocumentFrequency + 0.5) + 1)\n",
        "\n",
        "    # Calculate term frequency (number of times the token appears in the document)\n",
        "    TermFrequency = DocumentTokens.count(Token)\n",
        "\n",
        "    # Calculate the numerator part of the BM25 formula\n",
        "    Numerator = TermFrequency * (k1 + 1)\n",
        "\n",
        "    # Calculate the denominator part of the BM25 formula with document length adjustment\n",
        "    Denominator = TermFrequency + k1 * (1 - b + b * (DocumentLength / AverageDocumentLength))\n",
        "\n",
        "    # Accumulate the contribution of the current term to the document score\n",
        "    DocumentScore += InverseDocumentFrequency * (Numerator / Denominator)\n",
        "\n",
        "  # Return the final BM25 score for the document\n",
        "  return DocumentScore\n"
      ],
      "metadata": {
        "id": "npX2axskPF3b"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def OKAPI_BM25_DocumentRanking(QueryTokens, Documents, TokenFrequency, NumberOfTokens):\n",
        "  \"\"\"Ranks documents based on their similarity to a query using OKAPI BM25 model.\n",
        "\n",
        "  This function implements the OKAPI BM25 (Okapi Best Matching 25) document ranking algorithm,\n",
        "  a variant of the BM25 model. It calculates a score for each document in the collection based on\n",
        "  the query terms and factors like document frequency, term frequency, document length, and average\n",
        "  document length.\n",
        "\n",
        "  Args:\n",
        "      QueryTokens (list): A list of tokens representing the query.\n",
        "      Documents (dict): A dictionary containing document IDs and text data.\n",
        "      TokenFrequency (dict, optional): A dictionary containing term frequencies within the collection (assumed pre-calculated).\n",
        "      NumberOfTokens (int): The total number of tokens in the collection (assumed pre-calculated).\n",
        "\n",
        "  Returns:\n",
        "      list: A list of tuples containing document IDs and their corresponding scores,\n",
        "            sorted in descending order of score (highest scoring documents first).\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a dictionary to store document scores with document IDs as keys and scores as values\n",
        "  DocumentScore = defaultdict(float)\n",
        "\n",
        "  # Iterate through each document ID and text data pair in the Documents dictionary\n",
        "  for DocumentID, DocumentContent in Documents.items():\n",
        "\n",
        "    # Preprocess the text data for the current document (tokenize, remove stop words, and stem)\n",
        "    DocumentTokens = PreProcessing_Text(DocumentID, DocumentContent)\n",
        "\n",
        "    # Calculate OKAPI BM25 score for the document based on query, document tokens, etc.\n",
        "    # (Assuming OKAPI_BM25_ScoreCalculation is defined elsewhere)\n",
        "    DocScore = OKAPI_BM25_ScoreCalculation(QueryTokens, DocumentTokens, TokenFrequency, NumberOfTokens)\n",
        "\n",
        "    # Add the OKAPI BM25 score for the document to the DocumentScore dictionary\n",
        "    DocumentScore[DocumentID] = DocScore\n",
        "\n",
        "  # Sort the document scores in descending order (highest scoring documents first)\n",
        "  # Use itemgetter(1) to sort based on the second element in each tuple (the score)\n",
        "  DocumentRanking = sorted(DocumentScore.items(), key=itemgetter(1), reverse=True)\n",
        "\n",
        "  # Return the list of ranked documents (document ID, score)\n",
        "  return DocumentRanking\n"
      ],
      "metadata": {
        "id": "9DxbwoNVPZXz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def OKAPI_BM25_ScoreCalculation(QueryTokens, DocumentTokens, TermFrequencyInCollection, NumberOfTokens):\n",
        "  \"\"\"Calculates the OKAPI BM25 score for a document given a query and collection parameters.\n",
        "\n",
        "  This function implements the OKAPI BM25 (Okapi Best Matching 25) document scoring formula,\n",
        "  a variant of the BM25 model. It considers factors like query terms, document frequency within\n",
        "  the document (term frequency, TF), document length, average document length (implicit here),\n",
        "  and a smoothing parameter (lambda).\n",
        "\n",
        "  Args:\n",
        "      QueryTokens (list): A list of tokens representing the query terms.\n",
        "      DocumentTokens (list): A list of tokens representing the preprocessed document text.\n",
        "      TermFrequencyInCollection (dict): A dictionary containing term frequencies for all terms in the collection.\n",
        "      NumberOfTokens (int): The total number of tokens in the collection.\n",
        "\n",
        "  Returns:\n",
        "      float: The OKAPI BM25 score for the document relative to the query.\n",
        "  \"\"\"\n",
        "\n",
        "  # Smoothing parameter for OKAPI BM25 (default value)\n",
        "  lambd = 0.5\n",
        "\n",
        "  # Initialize document score to 1 (common starting point for BM25 variants)\n",
        "  DocumentScore = 1\n",
        "\n",
        "  # Get the length of the document (number of tokens)\n",
        "  DocumentLength = len(DocumentTokens)\n",
        "\n",
        "  # Iterate through each token in the query\n",
        "  for Token in QueryTokens:\n",
        "\n",
        "    # Count the term frequency (number of times the token appears) in the document\n",
        "    TermFrequency = DocumentTokens.count(Token)\n",
        "\n",
        "    # Calculate the probability considering document-specific TF and collection-level TF with smoothing\n",
        "    probability = (1 - lambd) * (TermFrequency / DocumentLength) + lambd * (TermFrequencyInCollection.get(Token, 0) / NumberOfTokens)\n",
        "\n",
        "    # Update the document score by accumulating the probability for each query term\n",
        "    DocumentScore *= probability\n",
        "\n",
        "  # Return the final OKAPI BM25 score for the document\n",
        "  return DocumentScore\n"
      ],
      "metadata": {
        "id": "D1x1ZezEQAOx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The main function is executed only when the script is run directly (not imported as a module)\n",
        "if __name__ == '__main__':\n",
        "\n",
        "  # Load the documents from the data file\n",
        "  Documents = load_passage(data_file)\n",
        "\n",
        "  # Preprocess the documents and generate the inverted index\n",
        "  Inverted_Index = Module_Inverted_Index(Documents)\n",
        "\n",
        "  # Calculate the inverse document frequency (IDF) for all terms in the inverted index\n",
        "  NumberOfDocuments = len(Documents)\n",
        "  InverseDocumentFrequency = Calculate_InverseDocumentFrequency(Inverted_Index, NumberOfDocuments)\n",
        "\n",
        "  # Load the queries from the query file\n",
        "  Queries = Load_Queries(query_file)\n",
        "\n",
        "  # ==================== VSM Model ====================\n",
        "\n",
        "  # Create the term-document matrix (may involve TF-IDF weighting) - likely implemented in Module_Term_Document_Matrix\n",
        "  Term_Document_Matrix = Module_Term_Document_Matrix(Documents, Inverted_Index, InverseDocumentFrequency)\n",
        "\n",
        "  # Process each query using the VSM model\n",
        "  for Query_ID, Query_Content in Queries.items():\n",
        "    # Preprocess the query text\n",
        "    Query_Tokens = PreProcessing_Text(Query_ID, Query_Content)\n",
        "\n",
        "    # Rank documents using the VSM model (implementation assumed in VSM_DocumentRanking)\n",
        "    VectorSpaceModel_DocumentRanking = VSM_DocumentRanking(Query_Tokens, Term_Document_Matrix)\n",
        "\n",
        "    # Output top 100 ranked documents for the query using VSM in TREC format\n",
        "    Output_File(Query_ID, VectorSpaceModel_DocumentRanking[:100], 'VSM', Output_Directory)\n",
        "\n",
        "  # ==================== BM25 Model ====================\n",
        "\n",
        "  # Calculate the total length of all documents (for average document length calculation)\n",
        "  TotalLength = 0\n",
        "  for Document_ID, Document_Content in Documents.items():\n",
        "    TotalLength += len(PreProcessing_Text(Document_ID, Document_Content))\n",
        "\n",
        "  # Calculate the average document length\n",
        "  AverageDocumentLength = TotalLength / NumberOfDocuments\n",
        "\n",
        "  # Process each query using the BM25 model\n",
        "  for QueryID, QueryContent in Queries.items():\n",
        "    # Preprocess the query text\n",
        "    QueryToken = PreProcessing_Text(QueryID, QueryContent)\n",
        "\n",
        "    # Rank documents using the BM25 model (implementation assumed in BM25_DocumentRanking)\n",
        "    BestMatch25_DocumentRanking = BM25_DocumentRanking(QueryToken, Documents, Inverted_Index, NumberOfDocuments, AverageDocumentLength)\n",
        "\n",
        "    # Output top 100 ranked documents for the query using BM25 in TREC format\n",
        "    Output_File(QueryID, BestMatch25_DocumentRanking[:100], 'BM25', Output_Directory)\n",
        "\n",
        "  # ==================== OKAPI BM25 Model ====================\n",
        "\n",
        "  # Pre-calculate term frequencies within the collection\n",
        "  TokenFrequency = defaultdict(int)\n",
        "  NumberOfToken = 0\n",
        "  for DocumentID, DocumentContent in Documents.items():\n",
        "    DocumentTokens = PreProcessing_Text(DocumentID, DocumentContent)\n",
        "    for Token in DocumentTokens:\n",
        "      TokenFrequency[Token] += 1\n",
        "      NumberOfToken += 1\n",
        "\n",
        "  # Process each query using the OKAPI BM25 model\n",
        "  for QueryID, QueryContent in Queries.items():\n",
        "    # Preprocess the query text\n",
        "    QueryTokens = PreProcessing_Text(QueryID, QueryContent)\n",
        "\n",
        "    # Rank documents using the OKAPI BM25 model (implementation assumed in OKAPI_BM25_DocumentRanking)\n",
        "    OKAPI_DocumentRanking = OKAPI_BM25_DocumentRanking(QueryTokens, Documents, TokenFrequency, NumberOfToken)\n",
        "\n",
        "    # Output top 100 ranked documents for the query using OKAPI BM25 in TREC format\n",
        "    Output_File(QueryID, OKAPI_DocumentRanking[:100], 'OKAPI_BM25', Output_Directory)\n",
        "\n",
        "  # ==================== Evaluation ====================\n",
        "\n",
        "  # Path to the TREC_EVAL tool (assumed to be accessible)\n",
        "  trec_eval_path = 'https://drive.google.com/file/d/1cwvL5uHI7OxmSMqLShZMEJ-J4VeijMfk/view?usp=drive_link'\n",
        "\n",
        "  # Path to the qrel file containing relevance judgments (assumed to be available)\n",
        "  qrel_file_path = comp_file\n",
        "\n",
        "  # Compute evaluation metrics for VSM model\n",
        "  vsm_output_file_path = os.path.join(Output_Directory, 'vsm_output.txt')\n",
        "  subprocess.run([trec_eval_path, qrel_file_path, vsm_output_file_path])\n",
        "\n",
        "  # Compute evaluation metrics for BM25 model\n",
        "  bm25_output_file_path = os.path.join(Output_Directory, 'bm25_output.txt')\n",
        "  subprocess.run([trec_eval_path, qrel_file_path, bm25_output_file_path])\n",
        "\n",
        "  # Compute evaluation metrics for Okapi BM25 model\n",
        "  okapi_bm25_output_file_path = os.path.join(Output_Directory, 'okapi_bm25_output.txt')\n",
        "  subprocess.run([trec_eval_path, qrel_file_path, okapi_bm25_output_file_path])\n"
      ],
      "metadata": {
        "id": "cYPHmHK8QR-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ESUjA_mvQ1s-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}